{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from access.ipynb\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from selenium import webdriver\n",
    "import import_ipynb\n",
    "from access import username, password, dbname, dbpass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_between(s, start, end):\n",
    "  return (s.split(start))[1].split(end)[0]\n",
    "\n",
    "def parse_html(request_url):\n",
    "    with requests.Session() as session:\n",
    "        post = session.post(\"https://m.facebook.com/login\", data={username,password})\n",
    "        parsed_html = session.get(request_url)\n",
    "    return parsed_html\n",
    "\n",
    "def title_scrap(post_id):\n",
    "    REQUEST_URL = f'https://m.facebook.com/story.php?story_fbid={post_id}&id=415518858611168'\n",
    "    soup = BeautifulSoup(parse_html(REQUEST_URL).content, \"html.parser\")\n",
    "    content = soup.find_all('p')\n",
    "    title = []\n",
    "    for lines in content:\n",
    "        title.append(lines.text)\n",
    "\n",
    "    title = ' '.join(title)    \n",
    "    return title\n",
    "\n",
    "def comments_scrap(post_id):\n",
    "    REQUEST_URL = f'https://mbasic.facebook.com/story.php?story_fbid={post_id}&id=415518858611168'\n",
    "    soup = BeautifulSoup(parse_html(REQUEST_URL).content, \"html.parser\")\n",
    "   \n",
    "    content = soup.find_all('div', attrs={'class' : True})\n",
    "    strs = []\n",
    "    comments_end=False\n",
    "    page=0\n",
    "    while not comments_end:\n",
    "      REQUEST_URL = f'https://mbasic.facebook.com/story.php?story_fbid={post_id}&id=415518858611168&p={page}'\n",
    "      for t in content:\n",
    "          t = re.findall('</a></h3><div.*', str(t))\n",
    "          if t:\n",
    "              for n_t in t:\n",
    "                  div_content = n_t\n",
    "                  div_content = div_content.replace('</a></h3>', '')\n",
    "                  div_content = ((div_content.split('>')[1])).split('<')[0]\n",
    "                  if div_content not in strs:\n",
    "                      strs.append(div_content)\n",
    "              \n",
    "              #here we don't play with bot, but with links, if you increment the url, facebook will load more comments  \n",
    "              page+=10\n",
    "          else:\n",
    "              comments_end= True\n",
    "    \n",
    "    return strs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "#mongodb connection\n",
    "cluster=MongoClient(f'mongodb+srv://{dbname}:{dbpass}@cluster0.4frlm.mongodb.net/myFirstDatabase?retryWrites=true&w=majority')\n",
    "db=cluster[\"FB\"]\n",
    "collection=db[\"posts\"]\n",
    "\n",
    "#one post scrap\n",
    "def post_scrap(post_id):\n",
    "    title=title_scrap(post_id)\n",
    "    coms=comments_scrap(post_id)    \n",
    "    post={\"_id\":post_id,\"title\":title,\"comments\":coms}\n",
    "    collection.insert_one(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from time import sleep \n",
    "from webdriver_manager.chrome import ChromeDriverManager \n",
    "from selenium.webdriver.chrome.options import Options  \n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "#Here we imlement the human-bot \n",
    "def posts_access(key_words):\n",
    "    #get the research field like chirack jacques concatenated\n",
    "    keys=\" \".join(key_words)\n",
    "    \n",
    "    #we access facebook from basic not from www\n",
    "    REQUEST_URL = 'https://mbasic.facebook.com/'\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    \n",
    "    #open facebook page\n",
    "    driver.get(REQUEST_URL)\n",
    "                              \n",
    "    #click on notification form                            \n",
    "    l=driver.find_element_by_xpath(\"//button[@type='submit']\")\n",
    "    l.click()\n",
    "    sleep(1) \n",
    "    \n",
    "    #enter username and pass to log in then wait \n",
    "    username_box = driver.find_element_by_id('m_login_email') \n",
    "    username_box.send_keys(username) \n",
    "    print (\"Email entered\") \n",
    "    password_box = driver.find_element_by_xpath(\"//input[@name='pass']\")\n",
    "    password_box.send_keys(password) \n",
    "    print (\"Password entered\")\n",
    "    sleep(1)\n",
    "    \n",
    "    #click on login button then wait for cookies alert\n",
    "    login_box = driver.find_element_by_xpath(\"//input[@value='Log In']\")\n",
    "    login_box.click() \n",
    "    sleep(2)\n",
    "    \n",
    "    \n",
    "    #click on cookies alert\n",
    "    verif_box = driver.find_element_by_xpath(\"//input[@value='OK']\")\n",
    "    verif_box.click()     \n",
    "    sleep(1)\n",
    "     \n",
    "    #to disable cookies won't reappear    \n",
    "    driver.cookies_enabled = False\n",
    "    \n",
    "    #facultaive, sometimes the cookies alert block the mbasic form, so re refresh to ensure that the bot is connected\n",
    "    driver.get(REQUEST_URL)\n",
    "    sleep(3)\n",
    "    \n",
    "\n",
    "    #search for keys on facebook search bar like the example: 'jacques chirac décès' here\n",
    "    search_box = driver.find_element_by_xpath(\"//input[@name='query']\")\n",
    "    search_box.send_keys(keys) \n",
    "    \n",
    "    #click on search\n",
    "    search_button=driver.find_element_by_xpath(\"//input[@type='submit']\")\n",
    "    search_button.click() \n",
    "    sleep(2)\n",
    "    \n",
    "                              \n",
    "    #seach only for posts, no people or pages, so click on more                    \n",
    "    more_button=driver.find_element_by_xpath(\"//a[@role='button']\")\n",
    "    more_button.click()\n",
    "    sleep(2)\n",
    "    \n",
    "    #then you click on posts\n",
    "    more_button=driver.find_element_by_xpath(\"//a[@role='menuitem']\" and \"//a[@aria-selected='false']\")\n",
    "    more_button.click()\n",
    "                        \n",
    "    #init a bool to ensure it won't infinetly loop\n",
    "    there_is_no_more_posts=False\n",
    "    while(not there_is_no_more_posts):\n",
    "        #parse the html code\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        #get all the a where there is links\n",
    "        content = soup.find_all('a',attrs={'href' : True})\n",
    "        \n",
    "        #get the href of each post, hidden on footer\n",
    "        ids = [\n",
    "        footer.find(\"a\")[\"href\"] for footer in \n",
    "        BeautifulSoup(html, \"html.parser\").find_all(\"footer\")\n",
    "        ]\n",
    "        for oneid in ids:\n",
    "            \n",
    "            #check if the id exist, then get the post id\n",
    "            if re.search(\"fbid\", oneid):\n",
    "                post_scrap(find_between(oneid,\"fbid=\",\"&id\"))\n",
    "\n",
    "        sleep(2)\n",
    "        try:\n",
    "            #at the end to see more button won't display, so we handle the exception\n",
    "            more_button=driver.find_element_by_xpath(\"//div[@id='see_more_pager']/a[1]\")\n",
    "            more_button.click()\n",
    "        except NoSuchElementException:\n",
    "            #to not risk an infinite loop \n",
    "            there_is_no_more_posts= True\n",
    "        \n",
    "        \n",
    "    \n",
    "    #end of the process\n",
    "    print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 89.0.4389\n",
      "[WDM] - Get LATEST driver version for 89.0.4389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver [C:\\Users\\mounir\\.wdm\\drivers\\chromedriver\\win32\\89.0.4389.23\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open facebook\n",
      "Email entered\n",
      "Password entered\n"
     ]
    }
   ],
   "source": [
    "key_words=['décès','chirac','jacques']\n",
    "posts_access(key_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
